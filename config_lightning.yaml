# MEDAF Multi-Label Classification Configuration - Lightning Version

# Dataset Configuration
data:
  source: "chestxray"  # Required by ConfigManager validation
  train_csv: "datasets/data/NIH/Data_Entry_2017.csv"
  test_csv: "datasets/data/NIH/Data_Entry_2017.csv"  # Same as train_csv for full dataset
  train_list: "datasets/data/NIH/train_val_list.txt"
  test_list: "datasets/data/NIH/test_list.txt"
  image_root: "datasets/data/NIH/images-224"
  img_size: 224
  max_samples: null # Set to integer for quick experiments, null for full dataset

# Training Configuration - Updated for DenseNet-121 with Focal Loss
training:
  batch_size: 32
  num_epochs: 100  # Increased for better convergence with lower LR
  learning_rate: 0.00005  # As specified: 0.00005
  weight_decay: 1e-4  # Standard weight decay for AdamW
  val_ratio: 0.1
  num_workers: 8  # Increased for better performance
  use_stratified_split: false # Enable stratified split for better class balance
  use_optimal_thresholds: true
  create_roc_plots: true # Create ROC curve plots during evaluation

  # Optimizer Configuration
  optimizer:
    type: "adamw" # adamw, adam, sgd
    betas: [0.9, 0.999]
    eps: 1e-8
    amsgrad: false

  # Learning Rate Scheduler Configuration - ReduceLROnPlateau as specified
  scheduler:
    enabled: true
    type: "plateau" # ReduceLROnPlateau as specified
    # For cosine scheduler
    eta_min: 1e-6
    # For step scheduler
    step_size: 10
    gamma: 0.1
    # For plateau scheduler
    factor: 0.5  # Reduce LR by half when plateau is detected
    patience: 5  # Wait 5 epochs before reducing LR
    min_lr: 1e-7  # Minimum learning rate

  # Loss Configuration - Focal Loss as specified
  loss:
    type: "focal" # Focal Loss as specified
    focal_alpha: 0.25  # Adjusted for multi-label: alpha=0.25 (prevents zero loss for negative samples)
    focal_gamma: 2.0  # As specified: gamma=2
    class_weighting:
      enabled: true
      method: "inverse_freq" # inverse_freq, effective_num, focal

  # Early Stopping Configuration
  early_stopping:
    patience: 15  # Increased patience for lower LR training
    min_delta: 1e-6
    monitor: "val/loss"
    mode: "min"

# Model Configuration - DenseNet-121 as specified
model:
  backbone: "densenet121"  # DenseNet-121 as specified
  num_classes: 14
  gate_temp: 100

  # Loss weights: [expert_weight, gate_weight, diversity_weight]
  loss_weights: [0.7, 1.0, 0.01]

  # Keys for tracking
  loss_keys: ["b1", "b2", "b3", "gate", "divAttn", "total"]
  acc_keys: ["acc1", "acc2", "acc3", "accGate"]

# Checkpoint Configuration
checkpoints:
  dir: "checkpoints/medaf_densenet_focal"
  save_every_n_epochs: 10  # Save checkpoint every 10 epochs
  save_top_k: 3  # Keep top K best models
  save_last: true  # Always save the last checkpoint


# Logging Configuration
logging:
  level: "INFO" # DEBUG, INFO, WARNING, ERROR
  metrics_dir: "logs/densenet_focal"

# Hardware Configuration
hardware:
  device: "auto" # auto, cuda, cpu, mps
  mixed_precision: true # Enable mixed precision for DenseNet efficiency
  memory_fraction: 0.9
  pin_memory: true

# Class Names (for ChestX-ray14)
class_names:
  - "Atelectasis"
  - "Cardiomegaly"
  - "Effusion"
  - "Infiltration"
  - "Mass"
  - "Nodule"
  - "Pneumonia"
  - "Pneumothorax" # first 8 classes
  - "Consolidation"
  - "Edema"
  - "Emphysema"
  - "Fibrosis"
  - "Pleural_Thickening"
  - "Hernia" # last 6 classes

# Novelty Detection Configuration
novelty_detection:
  enabled: true # Enable novelty detection evaluation
  gamma: 1.0 # Weight for feature-based score in hybrid computation
  temperature: 1.0 # Temperature for logit-based energy computation
  fpr_target: 0.05 # Target false positive rate for threshold calibration (5%)
  max_unknown_samples: null # Maximum unknown samples for evaluation (null = all)

# Reproducibility
seed: 42
